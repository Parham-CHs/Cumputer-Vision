{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Speed Check\n",
    "### Complete # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dlib\n",
      "  Using cached dlib-20.0.0.tar.gz (3.3 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: dlib\n",
      "  Building wheel for dlib (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dlib: filename=dlib-20.0.0-cp311-cp311-macosx_15_0_arm64.whl size=2932509 sha256=56e629469ebdde99c65475462bcb1638467e943283698c80c6ac715076b2cd20\n",
      "  Stored in directory: /Users/tahamajs/Library/Caches/pip/wheels/fa/e4/82/70875120d8e3f04c437bff144da98429352b3b026553d77b50\n",
      "Successfully built dlib\n",
      "Installing collected packages: dlib\n",
      "Successfully installed dlib-20.0.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "!pip install dlib\n",
    "import dlib\n",
    "import time\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Haar Cascade model from: models/myhaar.xml\n",
      "Loading video from: videos/cars.mp4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MODEL_ADDRESS = os.path.join(\"models\", \"myhaar.xml\") \n",
    "\n",
    "VIDEO_ADDRESS = os.path.join(\"videos\", \"cars.mp4\")\n",
    "\n",
    "print(f\"Loading Haar Cascade model from: {MODEL_ADDRESS}\")\n",
    "if not os.path.exists(MODEL_ADDRESS):\n",
    "    print(f\"Error: Haar Cascade model file not found at {MODEL_ADDRESS}\")\n",
    "    carCascade = None # TODO\n",
    "else:\n",
    "    carCascade = cv2.CascadeClassifier(MODEL_ADDRESS) # TODO\n",
    "    if carCascade.empty():\n",
    "        print(f\"Error: Failed to load Haar Cascade model from {MODEL_ADDRESS}. File might be corrupted or invalid.\")\n",
    "        carCascade = None \n",
    "\n",
    "print(f\"Loading video from: {VIDEO_ADDRESS}\")\n",
    "if not os.path.exists(VIDEO_ADDRESS):\n",
    "    print(f\"Error: Video file not found at {VIDEO_ADDRESS}\")\n",
    "    video = None # TODO\n",
    "else:\n",
    "    video = cv2.VideoCapture(VIDEO_ADDRESS) # TODO\n",
    "    if not video.isOpened():\n",
    "        print(f\"Error: Could not open video file {VIDEO_ADDRESS}.\")\n",
    "        video = None\n",
    "\n",
    "WIDTH = 1280  \n",
    "HEIGHT = 720  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python script sets up paths and attempts to load a Haar Cascade model and a video file using OpenCV.\n",
    "It defines `MODEL_ADDRESS` for the Haar model (\"models/myhaar.xml\") and `VIDEO_ADDRESS` for the video (\"videos/cars.mp4\"), then tries to load them, checking if files exist and if loading is successful.\n",
    "If the Haar model file isn't found or fails to load, `carCascade` is set to `None`.\n",
    "Similarly, if the video file is missing or cannot be opened, `video` is set to `None`.\n",
    "Finally, it defines `WIDTH` and `HEIGHT` constants (1280x720) for video processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 02:31:51.238 python[97842:4035961] +[IMKClient subclass]: chose IMKClient_Legacy\n",
      "2025-06-02 02:31:51.239 python[97842:4035961] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new tracker 0\n",
      "Creating new tracker 1\n",
      "Creating new tracker 2\n",
      "Creating new tracker 3\n",
      "Creating new tracker 4\n",
      "Creating new tracker 5\n",
      "Creating new tracker 6\n",
      "Creating new tracker 7\n",
      "Creating new tracker 8\n",
      "Creating new tracker 9\n",
      "Creating new tracker 10\n",
      "Creating new tracker 11\n",
      "Removing carID 0 from list of trackers.\n",
      "Removing carID 0 previous location.\n",
      "Removing carID 0 current location.\n",
      "Removing carID 5 from list of trackers.\n",
      "Removing carID 5 previous location.\n",
      "Removing carID 5 current location.\n",
      "Creating new tracker 12\n",
      "Removing carID 3 from list of trackers.\n",
      "Removing carID 3 previous location.\n",
      "Removing carID 3 current location.\n",
      "Creating new tracker 13\n",
      "Removing carID 4 from list of trackers.\n",
      "Removing carID 4 previous location.\n",
      "Removing carID 4 current location.\n",
      "Creating new tracker 14\n",
      "Creating new tracker 15\n",
      "Removing carID 15 from list of trackers.\n",
      "Removing carID 15 previous location.\n",
      "Removing carID 15 current location.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 141\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# Main function to start tracking\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m     trackMultipleObjects()\n",
      "Cell \u001b[0;32mIn[9], line 31\u001b[0m, in \u001b[0;36mtrackMultipleObjects\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# Record the start time for FPS calculation\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     rc, image \u001b[38;5;241m=\u001b[39m video\u001b[38;5;241m.\u001b[39mread()  \u001b[38;5;66;03m# Read a frame from the video\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(image) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def estimateSpeed(location1, location2):\n",
    "    d_pixels = math.sqrt(\n",
    "        math.pow(location2[0] - location1[0], 2)\n",
    "        + math.pow(location2[1] - location1[1], 2)\n",
    "    )\n",
    "    ppm = 8.8 \n",
    "    d_meters = d_pixels / ppm\n",
    "    fps = 18  \n",
    "    speed = d_meters * fps * 3.6  \n",
    "    return speed\n",
    "\n",
    "def trackMultipleObjects():\n",
    "    rectangleColor = (0, 255, 0) \n",
    "    frameCounter = 0 \n",
    "    currentCarID = 0 \n",
    "    fps = 0 \n",
    "\n",
    "    carTracker = {} \n",
    "    carLocation1 = {} \n",
    "    carLocation2 = {} \n",
    "    speed = [None] * 1000  \n",
    "\n",
    "    out = cv2.VideoWriter(\n",
    "        \"outpy.avi\", cv2.VideoWriter_fourcc(\"M\", \"J\", \"P\", \"G\"), 10, (WIDTH, HEIGHT)\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "        start_time = time.time() \n",
    "        rc, image = video.read()  \n",
    "        if type(image) == type(None):\n",
    "            break\n",
    "\n",
    "        image = cv2.resize(image, (WIDTH, HEIGHT)) \n",
    "        resultImage = image.copy() \n",
    "\n",
    "        frameCounter = frameCounter + 1  \n",
    "\n",
    "        carIDtoDelete = [] \n",
    "\n",
    "        for carID in carTracker.keys():\n",
    "            trackingQuality = carTracker[carID].update(image)\n",
    "            if trackingQuality < 7:\n",
    "                carIDtoDelete.append(carID)\n",
    "\n",
    "        for carID in carIDtoDelete:\n",
    "            print(\"Removing carID \" + str(carID) + \" from list of trackers.\")\n",
    "            print(\"Removing carID \" + str(carID) + \" previous location.\")\n",
    "            print(\"Removing carID \" + str(carID) + \" current location.\")\n",
    "            carTracker.pop(carID, None)\n",
    "            carLocation1.pop(carID, None)\n",
    "            carLocation2.pop(carID, None)\n",
    "\n",
    "        if not (frameCounter % 10):\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            cars = carCascade.detectMultiScale(gray, 1.1, 13, 18, (24, 24))\n",
    "            for _x, _y, _w, _h in cars:\n",
    "                x = int(_x)\n",
    "                y = int(_y)\n",
    "                w = int(_w)\n",
    "                h = int(_h)\n",
    "                x_bar = x + 0.5 * w\n",
    "                y_bar = y + 0.5 * h\n",
    "                matchCarID = None\n",
    "\n",
    "                for carID in carTracker.keys():\n",
    "                    trackedPosition = carTracker[carID].get_position()\n",
    "                    t_x = int(trackedPosition.left())\n",
    "                    t_y = int(trackedPosition.top())\n",
    "                    t_w = int(trackedPosition.width())\n",
    "                    t_h = int(trackedPosition.height())\n",
    "                    t_x_bar = t_x + 0.5 * t_w\n",
    "                    t_y_bar = t_y + 0.5 * t_h\n",
    "                    if (\n",
    "                        (t_x <= x_bar <= (t_x + t_w))\n",
    "                        and (t_y <= y_bar <= (t_y + t_h))\n",
    "                        and (x <= t_x_bar <= (x + w))\n",
    "                        and (y <= t_y_bar <= (y + h))\n",
    "                    ):\n",
    "                        matchCarID = carID\n",
    "\n",
    "                if matchCarID is None:\n",
    "                    print(\"Creating new tracker \" + str(currentCarID))\n",
    "                    tracker = dlib.correlation_tracker()\n",
    "                    tracker.start_track(image, dlib.rectangle(x, y, x + w, y + h))\n",
    "                    carTracker[currentCarID] = tracker\n",
    "                    carLocation1[currentCarID] = [x, y, w, h]\n",
    "                    currentCarID = currentCarID + 1\n",
    "\n",
    "        for carID in carTracker.keys():\n",
    "            trackedPosition = carTracker[carID].get_position()\n",
    "            t_x = int(trackedPosition.left())\n",
    "            t_y = int(trackedPosition.top())\n",
    "            t_w = int(trackedPosition.width())\n",
    "            t_h = int(trackedPosition.height())\n",
    "            cv2.rectangle(\n",
    "                resultImage, (t_x, t_y), (t_x + t_w, t_y + t_h), rectangleColor, 4\n",
    "            )\n",
    "            carLocation2[carID] = [t_x, t_y, t_w, t_h]\n",
    "\n",
    "        end_time = time.time()  \n",
    "        if not (end_time == start_time):\n",
    "            fps = 1.0 / (end_time - start_time)\n",
    "\n",
    "        for i in carLocation1.keys():\n",
    "            if frameCounter % 1 == 0:\n",
    "                [x1, y1, w1, h1] = carLocation1[i]\n",
    "                [x2, y2, w2, h2] = carLocation2[i]\n",
    "                carLocation1[i] = [x2, y2, w2, h2]\n",
    "                if [x1, y1, w1, h1] != [x2, y2, w2, h2]:\n",
    "                    if (speed[i] == None or speed[i] == 0) and y1 >= 275 and y1 <= 285:\n",
    "                        speed[i] = estimateSpeed([x1, y1, w1, h1], [x2, y2, w2, h2])\n",
    "                    if speed[i] != None and y1 >= 180:\n",
    "                        cv2.putText(\n",
    "                            resultImage,\n",
    "                            str(int(speed[i])) + \" km/hr\",\n",
    "                            (int(x1 + w1 / 2), int(y1 - 5)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.75,\n",
    "                            (255, 255, 255),\n",
    "                            2,\n",
    "                        )\n",
    "\n",
    "        cv2.imshow(\"result\", resultImage)\n",
    "        if cv2.waitKey(33) == 27:\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trackMultipleObjects()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python script is designed to detect, track, and estimate the speed of cars in a video.\n",
    "\n",
    "The `estimateSpeed` function takes two location points of a car as input. It calculates the pixel distance between these points, converts it to meters using a predefined pixels-per-meter ratio (ppm = 8.8), and then, using a fixed FPS (18), it computes the speed in kilometers per hour. This estimated speed is then returned.\n",
    "\n",
    "The `trackMultipleObjects` function processes a video stream frame by frame. It uses a Haar Cascade model (`carCascade`) for initial car detection every 10 frames and dlib correlation trackers for continuous tracking. New trackers are created for newly detected cars, and existing trackers are updated or removed based on tracking quality. For each tracked car, its speed is estimated using `estimateSpeed` when it crosses a virtual line, and this information, along with bounding boxes, is displayed on the output video, which is also saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonProject1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
